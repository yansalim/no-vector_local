# Vectorless PDF Chatbot

A revolutionary PDF chatbot that uses **no vector embeddings** or traditional RAG. Instead, it leverages Large Language Models for intelligent document selection and page relevance detection, providing a completely stateless and privacy-first experience.

## ğŸš€ What Makes This "Vectorless"?

Traditional PDF chatbots convert documents into vector embeddings for semantic search. This approach:
- **âŒ Requires expensive vector databases**
- **âŒ Needs pre-processing and indexing**
- **âŒ Stores document data on servers**
- **âŒ Loses context and nuance in embeddings**

Our **Vectorless** approach:
- **âœ… Uses LLM reasoning instead of vectors**
- **âœ… Processes documents in real-time**
- **âœ… Completely stateless - no server storage**
- **âœ… Preserves full document context**
- **âœ… Privacy-first - documents stay in your browser**

## ğŸ§  How the Vectorless Process Works

### 3-Step Intelligent Document Analysis

```mermaid
graph TD
    A[ğŸ“„ User uploads PDFs] --> B[ğŸ§  LLM Document Selection]
    B --> C[ğŸ¯ LLM Page Relevance Detection]
    C --> D[ğŸ’¬ Contextual Answer Generation]
    
    B --> B1[Analyzes collection description<br/>+ document filenames<br/>+ user question]
    C --> C1[Examines actual page content<br/>from selected documents<br/>in parallel processing]
    D --> D1[Generates comprehensive answer<br/>with proper citations]
```

### Step 1: ğŸ§  **Smart Document Selection**
- LLM reads your collection description and document filenames
- Intelligently selects which documents are likely to contain relevant information
- No embeddings needed - uses reasoning and context understanding

### Step 2: ğŸ¯ **Page Relevance Detection**
- LLM examines actual page content from selected documents
- Processes multiple documents in parallel for speed
- Identifies the most relevant pages based on question context

### Step 3: ğŸ’¬ **Contextual Answer Generation**
- Uses only the relevant pages to generate accurate answers
- Maintains full document context and nuance
- Provides proper citations and references

## âœ¨ Key Features

### ğŸ”’ **Privacy-First & Stateless**
- **Zero Server Storage**: Documents processed and stored entirely in your browser
- **LocalStorage Persistence**: Your documents persist across browser sessions
- **No Data Leakage**: Document content never persists on servers
- **Serverless-Friendly**: Perfect for Vercel/Netlify deployments

### ğŸ“ **Advanced File Handling**
- **Up to 100 PDF documents** per session
- **Chunked Upload System**: Automatically handles large file sets (>4.5MB)
- **4.5MB per file limit** - processes substantial documents
- **Real-time Processing**: No pre-indexing required

### ğŸ’¡ **Intelligent Processing**
- **Multi-Model Support**: GPT-4, GPT-5-mini, and more
- **Parallel Processing**: Multiple documents analyzed simultaneously
- **Context Preservation**: Full document context maintained throughout
- **Dynamic Descriptions**: Edit collection descriptions anytime

### ğŸ¨ **Modern Interface**
- **Responsive Design**: Works on desktop and mobile
- **Real-time Progress**: Visual feedback during uploads and processing
- **GitHub Integration**: Easy access to source code
- **Error Handling**: Comprehensive error messages and recovery

## ğŸ›  Technology Stack

### Frontend
- **Next.js 15**: React framework with App Router
- **TypeScript**: Type safety and better development experience
- **Tailwind CSS**: Modern utility-first styling
- **Lucide React**: Beautiful, consistent icons

### Backend (Vercel Functions)
- **Python Functions**: Serverless API endpoints
- **PyPDF2**: Reliable PDF text extraction
- **OpenAI GPT**: Advanced language models for reasoning
- **Chunked Processing**: Handle large uploads efficiently

### Infrastructure
- **Vercel Deployment**: Seamless serverless hosting
- **No Databases**: Completely stateless architecture
- **Automatic Scaling**: Handle traffic spikes effortlessly

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ and npm
- OpenAI API key

### 1. Clone and Install
```bash
git clone https://github.com/roe-ai/vectorless-chatbot.git
cd vectorless-chatbot
npm install
```

### 2. Environment Setup
Create `.env.local`:
```bash
# Only needed for local development
OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Run Locally
```bash
npm run dev
```
Visit http://localhost:3000

### 4. Deploy to Vercel
1. Push to GitHub
2. Connect to Vercel
3. Set environment variable: `OPENAI_API_KEY=your_key`
4. Deploy! âœ…

## ğŸ“– How to Use

### 1. **Upload Your Documents**
- Click "Add Your First Document" or "Add Files"
- Select up to 100 PDF files (4.5MB each max)
- Add a description of your document collection
- Large uploads are automatically chunked for reliability

### 2. **Start Chatting**
- Ask questions about your documents in natural language
- Watch the 3-step process: Document Selection â†’ Page Detection â†’ Answer Generation
- Get detailed answers with timing and cost breakdowns

### 3. **Manage Your Collection**
- Add more documents anytime
- Edit collection descriptions
- Start new sessions as needed
- All data stays in your browser

## ğŸ— Architecture Deep Dive

### Stateless Design
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser       â”‚    â”‚  Vercel Functions â”‚    â”‚   OpenAI API    â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ LocalStorage  â”‚â—„â”€â”€â–ºâ”‚ â€¢ /api/upload    â”‚â—„â”€â”€â–ºâ”‚ â€¢ GPT Models    â”‚
â”‚ â€¢ Document Data â”‚    â”‚ â€¢ /api/chat/streamâ”‚    â”‚ â€¢ Real-time     â”‚
â”‚ â€¢ Chat History  â”‚    â”‚ â€¢ No Storage     â”‚    â”‚   Processing    â”‚
â”‚ â€¢ Session State â”‚    â”‚ â€¢ Stateless      â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chunked Upload System
When uploading large document sets:
1. **Size Detection**: Frontend calculates total upload size
2. **Automatic Chunking**: Splits into 3.5MB chunks if needed
3. **Parallel Processing**: Each chunk processed independently
4. **Progressive Results**: Documents become available as chunks complete
5. **Error Recovery**: Failed chunks can be retried individually

## ğŸ”§ API Endpoints

### `POST /api/upload`
Upload and process PDF documents
- **Input**: FormData with files and description
- **Output**: Processed documents with extracted text
- **Features**: Automatic chunking, progress tracking

### `POST /api/chat/stream`
Stream chat responses in real-time
- **Input**: Question, documents, chat history
- **Output**: Server-sent events with processing steps
- **Features**: Real-time progress, cost tracking, citations

### `GET /api/health`
Service health check
- **Output**: System status and mode information

## ğŸ¯ Advantages Over Traditional RAG

| Traditional RAG | Vectorless Approach |
|----------------|---------------------|
| ğŸ—„ï¸ Requires vector database | ğŸš« No database needed |
| ğŸ“Š Pre-processes to embeddings | ğŸ”„ Real-time processing |
| ğŸ’° Expensive infrastructure | ğŸ’¸ Serverless & cost-effective |
| ğŸ”’ Stores data on servers | ğŸ›¡ï¸ Browser-only storage |
| ğŸ“ Limited by embedding dimensions | ğŸ§  Full context understanding |
| âš¡ Fast retrieval, lossy context | ğŸ¯ Accurate reasoning, full context |

## ğŸŒŸ Example Workflow

1. **Upload**: Marketing team uploads 50 company PDFs
2. **Describe**: "Company policies, procedures, and guidelines"
3. **Ask**: "What is our remote work policy?"
4. **Process**:
   - ğŸ§  LLM selects "HR Handbook" and "Remote Work Guidelines"
   - ğŸ¯ Identifies relevant pages about remote work
   - ğŸ’¬ Generates comprehensive answer with citations
5. **Result**: Accurate answer in ~15 seconds with cost breakdown

## ğŸ”® Future Enhancements

- **Multi-format Support**: Word docs, PowerPoint, Excel
- **Advanced Citations**: Highlight exact text passages
- **Collaboration Features**: Share sessions with team members
- **Analytics Dashboard**: Usage patterns and insights
- **Custom Models**: Support for local and custom LLMs
- **Batch Operations**: Process multiple questions simultaneously

## ğŸ¤ Contributing

We welcome contributions! This project showcases how modern LLMs can replace traditional vector-based approaches while providing better accuracy and user experience.

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

â­ **Star us on GitHub** if you find this vectorless approach interesting!

Built with â¤ï¸ by [ROE AI Inc.](https://github.com/roe-ai)
